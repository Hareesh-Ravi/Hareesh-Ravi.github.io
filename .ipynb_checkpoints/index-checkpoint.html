---
layout: default
title: Hareesh Ravi
---

<div style="text-align:justify">
<font size="4" color="#000000" style="text-align:justify;background-color:transparent;">
<span style="line-height:1.5;text-align:justify;background-color:transparent">
<img src="/img/avatar.png" border="0" height="200" width="180" alt="avatar" align="left" style="border: none; float: left; margin: 40px 40px 100px 20px;border-radius: 50%;"> 
<br>
I am an Applied Research Scientist at Adobe's Applied Research team working on language-vision research and Generative AI. I completed my PhD from the <a href="https://www.cs.rutgers.edu/" target="_blank">CS</a> department at the 
<a href="https://ivi.cs.rutgers.edu/" target="_blank">Intelligent Visual Interfaces</a> lab in <a href="http://newbrunswick.rutgers.edu/?utm_source=rutgers.edu&amp;utm_medium=web&amp;utm_campaign=uwide_sliver" target="_blank">Rutgers University</a> 
. My PhD thesis was on Multimodal Story Comprehension, under the supervision of <a href="https://www.cs.rutgers.edu/~mk1353/" target="_blank"> Dr. Mubbasir Kapadia</a>
and <a href="http://gerard.demelo.org/" target="_blank">Dr. Gerard De Melo</a><span style="background-color:transparent">. 
My research interests are on joint understanding of images/videos and abstract/narrative text with applications to multimodal story comprehension. Specificaly, story illustration, visual storytelling, image captioning and text-to-image retreival/generation. Recently, I have been working on Diffusion Models for Image generation and editing. Some recent works are mentioned <a href="https://hareesh-ravi.github.io/research" target="_blank">here</a>. 
    
<br>
<h2>News</h2>
</font>
</div>
<div style="text-align:justify">
<font size="3" color="#000000" style="background-color:transparent;">
<ul>
<li> Mar 20, 2023: Our paper on PRedItOR: Inference time text guided image editing with Diffusion Prior is out on <a href="https://arxiv.org/abs/2302.07979" target="_blank">arXiv</a> </li>      
<li> Feb 10, 2023: Our paper on Enhancing Controllability in Diffusion Models with a new Generalized Composable formulation is out on <a href="https://arxiv.org/abs/2302.14368" target="_blank">arXiv</a> </li>    
<li>Jun 20, 2022: Our AESOP Dataset from ICCV 2021 is public at <a href="https://github.com/adobe-research/aesop" target="_blank">https://github.com/adobe-research/aesop</a> </li>
<li>Dec 1, 2021: Our paper on "Cross Modal Coherence for Text-to-Image Retrieval" is accepted at AAAI 2022. </li>
<li>Sep 7, 2021: I am joining Adobe's Sensei ML team as an Applied Research Scientist.</li>
<li>Aug 12, 2021: I have succesfully defended my PhD on Multimodal Story Comrpehension: Datasets, Tasks and Neural Methods.</li>
<li>July 22, 2021: Our paper "AESOP: Abstract Encoding of Stories, Objects and Pictures" is accepted to ICCV 2021 main conference. Paper, Dataset and Code to follow soon.</li>
<!-- <li>April 25, 2021: We received the Best Paper Award for our paper "Exploiting Image Text Synergy for Contextual Image Captioning", in LANTERN workshop associated with EACL 2021.</li>
<li>April 10, 2021: Code and Dataset for our paper "Exploiting Image Text Synergy for Contextual Image Captioning" is available <a href="https://github.com/Sreyasi/contextual_captions" target="_blank">here</a> -->
<li> ... </li> 
<li> ... </li> 
</ul>
</span>
</font>
</div>


