---
layout: default
title: Hareesh Ravi
---

<div style="text-align:justify">
<font size="4" color="#000000" style="text-align:justify;background-color:transparent;">
<span style="line-height:1.5;text-align:justify;background-color:transparent">
<img src="/img/avatar.png" border="0" height="200" width="180" alt="avatar" align="left" style="border: none; float: left; margin: 40px 40px 100px 20px;border-radius: 50%;"> 
<br>
I am an Applied Research Scientist at Adobe's Sensei ML team working on language-vision research. I completed my PhD from the <a href="https://www.cs.rutgers.edu/" target="_blank">CS</a> department at the 
<a href="https://ivi.cs.rutgers.edu/" target="_blank">Intelligent Visual Interfaces</a> lab in <a href="http://newbrunswick.rutgers.edu/?utm_source=rutgers.edu&amp;utm_medium=web&amp;utm_campaign=uwide_sliver" target="_blank">Rutgers University</a> 
. My PhD thesis was on Multimodal Story Comprehension, under the supervision of <a href="https://www.cs.rutgers.edu/~mk1353/" target="_blank"> Dr. Mubbasir Kapadia</a>
and <a href="http://gerard.demelo.org/" target="_blank">Dr. Gerard De Melo</a><span style="background-color:transparent">. 
I am interested in joint understanding of images/videos and abstract/narrative text with applications to multimodal story comprehension.
More specifically, it involves developing neural network models to learn various factors that govern multimodal story comprehension and evaluating on 
tasks such as story illustration, visual storytelling, image captioning and text-to-image retreival/generation.
<br>
<h2>News</h2>
</font>
</div>
<div style="text-align:justify">
<font size="3" color="#000000" style="background-color:transparent;">
<ul>
<li>Jun 20, 2022: Our AESOP Dataset from ICCV 2021 is public at <a href="https://github.com/adobe-research/aesop" target="_blank">https://github.com/adobe-research/aesop</a>
<li>Dec 1, 2021: Our paper on "Cross Modal Coherence for Text-to-Image Retrieval" is accepted at AAAI 2022. </li>
<li>Sep 7, 2021: I am joining Adobe's Sensei ML team as an Applied Research Scientist.</li>
<li>Aug 12, 2021: I have succesfully defended my PhD on Multimodal Story Comrpehension: Datasets, Tasks and Neural Methods.</li>
<li>July 22, 2021: Our paper "AESOP: Abstract Encoding of Stories, Objects and Pictures" is accepted to ICCV 2021 main conference. Paper, Dataset and Code to follow soon.</li>
<li>April 25, 2021: We received the Best Paper Award for our paper "Exploiting Image Text Synergy for Contextual Image Captioning", in LANTERN workshop associated with EACL 2021.</li>
<li>April 10, 2021: Code and Dataset for our paper "Exploiting Image Text Synergy for Contextual Image Captioning" is available <a href="https://github.com/Sreyasi/contextual_captions" target="_blank">here</a>
<li> ... </li>
</ul>
</span>
</font>
</div>


